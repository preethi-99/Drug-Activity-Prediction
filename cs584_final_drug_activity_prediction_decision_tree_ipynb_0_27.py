# -*- coding: utf-8 -*-
"""CS584- Final Drug Activity Prediction - Decision Tree.ipynb-0.27

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DennIG96dHxEXymtIGpRBvCXjbnxTH_c
"""

import numpy as np
import pandas as pd
import sklearn
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import roc_auc_score

import numpy as np
import pandas as pd

status = []
readings = []


with open('hw2_train_final_3.txt', 'r') as file:

    for line in file:

        parts = line.strip().split('\t', 1)
        if len(parts) == 2:
            act_status, lab_readings = parts
            status.append(act_status)

            readings.append(lab_readings)

train_df = pd.DataFrame({'Active Status': status,
                     'Readings': readings})

print(train_df)

train_df = train_df.join(train_df['Readings'].str.split(' ', expand=True).apply(pd.to_numeric, errors='coerce'))


train_df = train_df.drop(columns=['Readings'])

print(train_df)

train_df = train_df.fillna(train_df.mean())

print(train_df)

test_readings = []


with open('hw2_test_data_final_3.txt', 'r') as file:

    for line in file:

        parts = line.strip().split('\t', 1)
        if len(parts) == 1:
            lab_readings = parts
            test_readings.append(lab_readings)

test_df = pd.DataFrame({
                     'Readings': test_readings})

print(test_df)

import pandas as pd

test_df['Readings'] = test_df['Readings'].apply(lambda x: ' '.join(map(str, x)))


test_df['Readings'] = test_df['Readings'].str.strip('[]').str.split()


test_df = test_df['Readings'].apply(pd.Series)

test_df = test_df.apply(pd.to_numeric, errors='coerce')


test_df = test_df.dropna(axis=1, how='all')

print(test_df)

test_df = test_df.fillna(test_df.mean())

print(test_df)

from sklearn.preprocessing import StandardScaler


active_status = train_df['Active Status']


numerical_data = train_df.drop(columns=['Active Status'])


scaler = StandardScaler()
normalized_data = scaler.fit_transform(numerical_data)

normalized_df = pd.DataFrame(normalized_data, columns=numerical_data.columns)

normalized_df['Active Status'] = active_status

print(normalized_df)

test_numerical_data = test_df

scaler = StandardScaler()
test_normalized_data = scaler.fit_transform(test_numerical_data)

test_normalized_df = pd.DataFrame(test_normalized_data, columns=test_numerical_data.columns)

print(test_normalized_df)

from sklearn.decomposition import PCA
import pandas as pd

X = normalized_df.drop(columns=['Active Status'])
y = normalized_df['Active Status']

# Standardize the data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

n_components = 350
pca = PCA(n_components=n_components)


X_pca = pca.fit_transform(X_scaled)


pca_columns = [f'PCA_{i}' for i in range(n_components)]
X_pca_df = pd.DataFrame(data=X_pca, columns=pca_columns)

final_df = pd.concat([X_pca_df, y], axis=1)

print(final_df)

test_X = test_normalized_df
scaler = StandardScaler()
X_scaled_test = scaler.fit_transform(test_X)

n_components = 350
pca = PCA(n_components=n_components)


X_pca_test = pca.fit_transform(X_scaled_test)

pca_columns = [f'PCA_{i}' for i in range(n_components)]
X_pca_df_test = pd.DataFrame(data=X_pca_test, columns=pca_columns)

print(X_pca_df_test)

X = final_df.drop(columns=['Active Status'])
y = final_df['Active Status']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from imblearn.over_sampling import SMOTE
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split



smote = SMOTE(sampling_strategy='auto', random_state=42)


X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import f1_score


clf = DecisionTreeClassifier()


param_grid = {
    'max_depth': [None, 10, 20, 30],
    'criterion': ['gini', 'entropy']
}

grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_resampled, y_train_resampled)


best_model = grid_search.best_estimator_
best_params = grid_search.best_params_


test_accuracy = best_model.score(X_test, y_test)


predicted = cross_val_predict(best_model, X_train_resampled, y_train_resampled, cv=5)

f1 = f1_score(y_train_resampled, predicted,pos_label='1')


print("Best Model",best_model)
print("Best Parameters",best_params)
# Print the F1 score
print("F1 Score:", f1)

dt_classifier = DecisionTreeClassifier(max_depth=20, criterion='gini')

dt_classifier.fit(X, y)

y_pred_actual_test = dt_classifier.predict(X_pca_df_test)

print(y_pred_actual_test)

with open("predictions.txt", "w", encoding="utf-8") as file:
    for prediction in y_pred_actual_test:
        file.write(f"{prediction}\n")